Index: 01/main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n# Data definition (constant)\r\nDATA = np.array([\r\n    [ 2.00, 1.08, -0.83, -1.97, -1.31, 0.57 ],\r\n    [ 0.00, 1.68, 1.82, 0.28, -1.51, -1.91 ],\r\n    [ 1.00, 2.38, 2.49, 2.15, 2.59, 4.32 ]\r\n])\r\nDATA_T = DATA.T\r\nT = np.arange(1, len(DATA_T)+1)\r\n\r\nclass Model:\r\n    def __init__(self, degree: int):\r\n        \"\"\"Constructor.\r\n        \"\"\"\r\n        assert degree > 0\r\n        self.degree = degree\r\n\r\nclass Degree1(Model):\r\n    def __init__(self):\r\n        \"\"\"A child class inherited from class Model.\r\n        This models the drone's movement using degree 1 polynomial regression (constant velocity).\r\n        \"\"\"\r\n        super().__init__(degree=1)\r\n        self.A = np.array([\r\n            [1, 1, 1],  # [alpha_0, beta_0, gamma_0]\r\n            [1, 1, 1]   # [alpha_1, beta_1, gamma_1]\r\n        ], dtype=float)\r\n        self.error_arr = []\r\n        self.coef_arr = []\r\n        self.convergence_iter = None\r\n\r\n    def __str__(self):\r\n        pass\r\n\r\n    def cal_grad(self, x: np.ndarray, y: np.ndarray):\r\n        diff = self.A[0] + self.A[1] * x.reshape(-1, 1) - y  # Compute the term (A_0 + A_1*t - y)\r\n        gradient = 2 * np.array([\r\n            np.sum(diff, axis=0),       # First row: sum of (A_0 + A_1*t - y)\r\n            np.sum(x.reshape(-1, 1) * diff, axis=0)  # Second row: sum of t * (A_0 + A_1*t - y)\r\n        ])\r\n\r\n        return gradient\r\n        # return np.array([\r\n        #     [\r\n        #         sum([ 2*(self.A[0, 0] + self.A[1, 0]*t - p[0]) for t, p in zip(x, y) ]),\r\n        #         sum([ 2*(self.A[0, 1] + self.A[1, 1]*t - p[1]) for t, p in zip(x, y) ]),\r\n        #         sum([ 2*(self.A[0, 2] + self.A[1, 2]*t - p[2]) for t, p in zip(x, y) ])\r\n        #     ],\r\n        #     [\r\n        #         sum([ 2*t*(self.A[0, 0] + self.A[1, 0]*t - p[0]) for t, p in zip(x, y) ]),\r\n        #         sum([ 2*t*(self.A[0, 1] + self.A[1, 1]*t - p[1]) for t, p in zip(x, y) ]),\r\n        #         sum([ 2*t*(self.A[0, 2] + self.A[1, 2]*t - p[2]) for t, p in zip(x, y) ])\r\n        #     ]\r\n        # ])\r\n\r\n    def fit(self, x: np.ndarray, y: np.ndarray, lr: int, iter: int, ct: float):\r\n        assert len(x) == len(y)\r\n\r\n        n = len(x)\r\n        self.D = np.array([ np.full(n, 1), np.arange(1, n+1) ], dtype=float).transpose()\r\n        self.error = sum((y - np.dot(self.D, self.A))**2)\r\n        i = 0\r\n        while i < iter:\r\n            self.gradient = self.cal_grad(x, y)\r\n            self.A = self.A - lr * self.gradient\r\n            self.coef_arr.append(self.A)\r\n\r\n            # Compute error (squared error)\r\n            y_pred = np.dot(self.D, self.A)\r\n            error = np.sum((y - y_pred) ** 2)\r\n            self.error_arr.append(error)\r\n\r\n            # Check for convergence\r\n            if i > 0 and abs(self.error_arr[-1] - self.error_arr[-2]) < ct and self.convergence_iter is None:\r\n                self.convergence_iter = i  # Store the convergence iteration\r\n            i += 1\r\n           \r\n        # If no convergence detected based on threshold, mark last iteration as convergence\r\n        if self.convergence_iter is None:\r\n            self.convergence_iter = iter - 1\r\n\r\n    def plot(self, convergence_threshold=None):\r\n        plt.figure(figsize=(10, 6))\r\n        plt.plot(range(1, len(self.error_arr)+1), self.error_arr, marker='o', linestyle='-', color='b', label=\"Error\")\r\n\r\n        # Ensure convergence iteration is marked even if threshold not met\r\n        if hasattr(self, \"convergence_iter\") and self.convergence_iter is not None:\r\n            plt.axvline(self.convergence_iter, color='r', linestyle='--', label=f'Converged at {self.convergence_iter}')\r\n            param_values = self.coef_arr[self.convergence_iter]\r\n            param_text = f'Params:\\n{param_values}'\r\n            plt.annotate(f'Converged\\nIter: {self.convergence_iter}\\n{param_text}', \r\n                        xy=(self.convergence_iter, self.error_arr[self.convergence_iter]), \r\n                        xytext=(self.convergence_iter + 2, self.error_arr[self.convergence_iter] * 1.1),\r\n                        arrowprops=dict(arrowstyle='->', lw=1.5, color='red'),\r\n                        fontsize=10, color='red')\r\n\r\n        plt.xlabel('Iteration')\r\n        plt.ylabel('Error (Squared Error)')\r\n        plt.title('Error vs. Iterations')\r\n\r\n        # Show convergence threshold if provided\r\n        if convergence_threshold:\r\n            plt.axhline(convergence_threshold, color='g', linestyle=':', label=f'Threshold {convergence_threshold}')\r\n        \r\n        plt.legend()\r\n        plt.grid(True)\r\n        plt.show()\r\n\r\n\r\nclass Degree2(Model):\r\n    def __init__(self):\r\n        \"\"\"A child class inherited from class Model.\r\n        This models the drone's movement using degree 2 polynomial regression (constant acceleration).\r\n        \"\"\"\r\n        super().__init__(degree=2)\r\n        self.A = np.array([\r\n            [1, 1, 1],  # [alpha_0, beta_0, gamma_0]\r\n            [1, 1, 1],  # [alpha_1, beta_1, gamma_1]\r\n            [1, 1, 1]   # [alpha_2, beta_2, gamma_2]\r\n        ], dtype=float)\r\n        self.error_arr = []\r\n        self.coef_arr = []\r\n        self.convergence_iter = None\r\n\r\n    def __str__(self):\r\n        pass\r\n\r\n    def cal_grad(self, x: np.ndarray, y: np.ndarray):\r\n        diff = self.A[0] + self.A[1] * x.reshape(-1, 1) + self.A[2] * (x.reshape(-1, 1)**2) - y  # Compute the term (A_0 + A_1*t + A_2*t^2 - y)\r\n        gradient = 2 * np.array([\r\n            np.sum(diff, axis=0),                           # 1st row: sum of (A_0 + A_1*t + A_2*t^2 - y)\r\n            np.sum(x.reshape(-1, 1) * diff, axis=0),        # 2nd row: sum of t * (A_0 + A_1*t + A_2*t^2 - y)\r\n            np.sum((x.reshape(-1, 1)**2) * diff, axis=0)    # 3rd row: sum of t*t * (A_0 + A_1*t + A_2*t^2 - y)\r\n        ])\r\n\r\n        return gradient\r\n\r\n    def fit(self, x: np.ndarray, y: np.ndarray, lr: int, iter: int, ct: float):\r\n        assert len(x) == len(y)\r\n\r\n        n = len(x)\r\n        self.D = np.array([ np.full(n, 1), np.arange(1, n+1), (np.arange(1, n+1)**2)], dtype=float).transpose()\r\n        self.error = sum((y - np.dot(self.D, self.A))**2)\r\n        i = 0\r\n        while i < iter:\r\n            # print(\"iter:\", i)\r\n            self.gradient = self.cal_grad(x, y)\r\n            self.A = self.A - lr * self.gradient\r\n            self.coef_arr.append(self.A)\r\n\r\n            # Compute error (squared error)\r\n            y_pred = np.dot(self.D, self.A)\r\n            # print(\"y_pred:\\n\", y_pred)\r\n            error = np.sum((y - y_pred) ** 2)\r\n            self.error_arr.append(error)\r\n\r\n            # Check for convergence\r\n            if i > 0 and abs(self.error_arr[-1] - self.error_arr[-2]) < ct and self.convergence_iter is None:\r\n                self.convergence_iter = i  # Store the convergence iteration\r\n            i += 1\r\n           \r\n        # If no convergence detected based on threshold, mark last iteration as convergence\r\n        if self.convergence_iter is None:\r\n            self.convergence_iter = iter - 1\r\n\r\n    def plot(self, convergence_threshold=None):\r\n        plt.figure(figsize=(10, 6))\r\n        plt.plot(range(1, len(self.error_arr)+1), self.error_arr, marker='o', linestyle='-', color='b', label=\"Error\")\r\n\r\n        # Ensure convergence iteration is marked even if threshold not met\r\n        if hasattr(self, \"convergence_iter\") and self.convergence_iter is not None:\r\n            plt.axvline(self.convergence_iter+1, color='r', linestyle='--', label=f'Converged at {self.convergence_iter+1}')\r\n            param_values = self.coef_arr[self.convergence_iter]\r\n            param_text = f'Params:\\n{param_values}'\r\n            plt.annotate(f'Converged\\nIter: {self.convergence_iter+1}\\n{param_text}', \r\n                        xy=(self.convergence_iter+1, self.error_arr[self.convergence_iter]), \r\n                        xytext=(self.convergence_iter + 2, self.error_arr[self.convergence_iter] * 1.1),\r\n                        arrowprops=dict(arrowstyle='->', lw=1.5, color='red'),\r\n                        fontsize=10, color='red')\r\n\r\n        plt.xlabel('Iteration')\r\n        plt.ylabel('Error (Squared Error)')\r\n        plt.title('Error vs. Iterations')\r\n\r\n        # Show convergence threshold if provided\r\n        if convergence_threshold:\r\n            plt.axhline(convergence_threshold, color='g', linestyle=':', label=f'Threshold {convergence_threshold}')\r\n        \r\n        plt.legend()\r\n        plt.grid(True)\r\n        plt.show()\r\n\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    # Create argument parser\r\n    parser = argparse.ArgumentParser(description=\"Parse parameters in a POSIX-style.\")\r\n\r\n    # Add arguments\r\n    parser.add_argument(\"-lr\", \"--learning_rate\", type=float, help=\"Set the learning rate\", required=True, default=0.01)\r\n    parser.add_argument(\"-it\", \"--iterations\", type=int, help=\"Set the max iteration number\", required=True, default=20)\r\n    parser.add_argument(\"-d\", \"--degree\", type=int, help=\"Set the degree for the polynomial model\", choices=[1, 2], required=True, default=1)\r\n    parser.add_argument(\"-ct\", \"--convergence_threshold\", type=float, help=\"Set the convergence threshold\", default=1e-5)\r\n    \r\n    # Parse arguments\r\n    args = parser.parse_args()\r\n\r\n    # Use parsed arguments\r\n    lr = args.learning_rate\r\n    iter = args.iterations\r\n    deg = args.degree\r\n    ct = args.convergence_threshold\r\n    print(f\"Learning Rate: {lr}\")\r\n    print(f\"Iterations: {iter}\")\r\n    print(f\"Degree: {deg}\")\r\n\r\n    if deg == 1:\r\n        model = Degree1()\r\n    elif deg == 2:\r\n        model = Degree2()\r\n\r\n    model.fit(T, DATA_T, lr, iter, ct)\r\n    model.plot()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/01/main.py b/01/main.py
--- a/01/main.py	(revision 75843d1ab4d0f5326a1bd2e37891aff8cbccaa7f)
+++ b/01/main.py	(date 1739996335842)
@@ -78,6 +78,9 @@
             if i > 0 and abs(self.error_arr[-1] - self.error_arr[-2]) < ct and self.convergence_iter is None:
                 self.convergence_iter = i  # Store the convergence iteration
             i += 1
+
+        print(f"Residual error at iteration {i}: {self.error}")
+        print(sum(self.error_arr))
            
         # If no convergence detected based on threshold, mark last iteration as convergence
         if self.convergence_iter is None:
@@ -93,8 +96,8 @@
             param_values = self.coef_arr[self.convergence_iter]
             param_text = f'Params:\n{param_values}'
             plt.annotate(f'Converged\nIter: {self.convergence_iter}\n{param_text}', 
-                        xy=(self.convergence_iter, self.error_arr[self.convergence_iter]), 
-                        xytext=(self.convergence_iter + 2, self.error_arr[self.convergence_iter] * 1.1),
+                        xy=(self.convergence_iter, self.error_arr[self.convergence_iter]),
+                        xytext=(self.convergence_iter - 2, self.error_arr[self.convergence_iter] * 1.1),
                         arrowprops=dict(arrowstyle='->', lw=1.5, color='red'),
                         fontsize=10, color='red')
 
@@ -162,11 +165,16 @@
             if i > 0 and abs(self.error_arr[-1] - self.error_arr[-2]) < ct and self.convergence_iter is None:
                 self.convergence_iter = i  # Store the convergence iteration
             i += 1
+
+        print(f"Residual error at iteration {i}: {self.error}")
+        print(sum(self.error_arr))
            
         # If no convergence detected based on threshold, mark last iteration as convergence
         if self.convergence_iter is None:
             self.convergence_iter = iter - 1
 
+    def predict(self, x: np.ndarray):
+
     def plot(self, convergence_threshold=None):
         plt.figure(figsize=(10, 6))
         plt.plot(range(1, len(self.error_arr)+1), self.error_arr, marker='o', linestyle='-', color='b', label="Error")
